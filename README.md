# SEP: Computer Vision & Deep Learning Project

This project implements a Convolutional Neural Network (CNN) to classify facial emotions using the **RAF-DB (Real-world Affective Faces Database)**. It is part of the Software Development Practical Course (SEP).

## ðŸ‘¥ Team Members
* Alen Alija
* Kilian Killer
* Leon Maibauer
* Richard Tscharke

## ðŸ“‚ Project Structure

```text
.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ RAF_raw/             # Place original dataset here
â”‚   â””â”€â”€ RAF_processed/       # Generated by prepare_RAF_raw.py
â”œâ”€â”€ models/                  # Saved model checkpoints (*.pth)
â”œâ”€â”€ results/                 # Output CSVs and evaluation metrics
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ evaluate.py          # Generates confusion matrix & report
â”‚   â”œâ”€â”€ generate_csv.py      # Generates predictions.csv for submission
â”‚   â”œâ”€â”€ model.py             # CNN Architecture definition
â”‚   â”œâ”€â”€ prepare_RAF_raw.py   # Data preprocessing script
â”‚   â””â”€â”€ train.py             # Main training loop
â”œâ”€â”€ requirements.txt         # Python dependencies
â””â”€â”€ README.md


ðŸ› ï¸ Installation & Setup
1. Clone the repository (if not already done).
2. Create and activate a virtual environment (recommended):
   python3 -m venv .venv
   source .venv/bin/activate  # On Windows: .venv\Scripts\activate
3. Install dependencies:
   pip install -r requirements.txt


ðŸš€ Workflow
1. Data Preparation: Before training, the raw RAF-DB dataset must be processed and sorted into class-specific folders.
   I Place the raw RAF-DB images in data/RAF_raw/Image/aligned.
   III Place the label file at data/RAF_raw/EmoLabel/list_patition_label.txt.
   III Run the preparation script: 
     python src/prepare_RAF_raw.py
This creates the data/RAF_processed/ directory with train and test splits.

2. Training the Model: 
To train the CNN from scratch:
   python src/train.py
Input: Images from data/RAF_processed/train.
Output: Saves the best model weights to models/raf_cnn_vX.pth (automatically versioned).
Config: You can adjust BATCH_SIZE, LEARNING_RATE, and EPOCHS directly in src/train.py.

3. Evaluation:
To generate a classification report and a confusion matrix:
   I Ensure the correct model path is set in src/evaluate.py (variable MODEL_PATH).
   II Run:
      python src/evaluate.py
   III Output: Prints precision/recall/f1-score to console and saves confusion_matrix.png

4. Generate Submission CSV
To generate the required CSV file containing classification scores for the test set:
   python src/generate_csv.py
Output: Saves predictions.csv to the results/ folder.
Format: filename, Anger, Disgust, Fear, Happiness, Sadness, Surprise, prediction.

ðŸ§  Model Architecture
We utilize a custom CNN (CustomEmotionCNN) defined in src/model.py:
   Input: 64x64 RGB Images.
   Backbone: 4 Convolutional Blocks (Conv2d -> BatchNorm -> ReLU -> MaxPool).
   Classifier: Fully Connected layers with Dropout (0.5) for regularization.
   Classes: Anger, Disgust, Fear, Happiness, Sadness, Surprise.

ðŸ“Š Results
Current Accuracy: ~84% (Baseline Model v0)
Strongest Class: Happiness
Challenges: Distinguishing Fear vs. Surprise due to visual similarities and limited data representation.

University of Munich (LMU) - WiSe 25/26