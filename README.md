# SEP: Computer Vision & Deep Learning Project

This project implements a Convolutional Neural Network (CNN) to classify facial emotions using the **RAF-DB (Real-world Affective Faces Database)**. It is part of the Software Development Practical Course (SEP).

## ðŸ‘¥ Team Members
* Alen Alija
* Kilian Killer
* Leon Maibauer
* Richard Tscharke

## ðŸ“‚ Project Structure

```text
.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ RAF_raw/                # Place original dataset here (aligned & original folders)
â”‚   â”œâ”€â”€ RAF_aligned_processed/  # Generated by prepare_RAF_raw.py (used for training)
â”‚   â””â”€â”€ RAF_original_processed/ # Generated by prepare_RAF_raw.py (full size images)
â”œâ”€â”€ models/                  # Saved model checkpoints (*.pth)
â”œâ”€â”€ results/                 # Output CSVs and evaluation metrics
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ evaluate.py          # Generates confusion matrix & report
â”‚   â”œâ”€â”€ generate_csv.py      # Generates predictions.csv
â”‚   â”œâ”€â”€ model.py             # CNN Architecture definition
â”‚   â”œâ”€â”€ prepare_RAF_raw.py   # Data preprocessing script
â”‚   â””â”€â”€ train.py             # Main training loop
â”œâ”€â”€ requirements.txt         # Python dependencies
â””â”€â”€ README.md


ðŸ› ï¸ Installation & Setup
1. Clone the repository (if not already done).
2. Create and activate a virtual environment (recommended):
   python3 -m venv .venv
   source .venv/bin/activate  # On Windows: .venv\Scripts\activate
3. Install dependencies:
   pip install -r requirements.txt


ðŸš€ Workflow
1. Data Preparation: Before training, the raw RAF-DB dataset must be processed. This script sorts images into class-specific folders for both the **aligned** (cropped) and **original** (full-size) datasets.

   I Place the raw RAF-DB data in "data/RAF_raw/".
   II Run the preparation script: 
     python src/prepare_RAF_raw.py
This script creates two directories ("data/RAF_aligned_processed/" and "data/RAF_original_processed/"), each containing subfolders for the following emotions:*
    * ðŸ˜¡ **Anger**
    * ðŸ¤¢ **Disgust**
    * ðŸ˜± **Fear**
    * ðŸ˜„ **Happiness**
    * ðŸ˜¢ **Sadness**
    * ðŸ˜² **Surprise** 

2. Training the Model: 
To train the CNN from scratch:
   python src/train.py
Input: Images from data/RAF_aligned_processed/train. Or use the original Images 
Output: Saves the best model weights to models/raf_cnn_vX.pth (automatically versioned).
Config: You can adjust BATCH_SIZE, LEARNING_RATE, and EPOCHS directly in src/train.py.

3. Evaluation:
To generate a classification report and a confusion matrix:
   I Ensure the correct model path is set in src/evaluate.py (variable MODEL_PATH).
   II Run:
      python src/evaluate.py
   III Output: Prints precision/recall/f1-score to console and saves confusion_matrix.png

4. Generate Submission CSV
To generate the required CSV file containing classification scores for the test set:
   python src/generate_csv.py
Output: Saves predictions.csv to the results/ folder.
Format: filename, Anger, Disgust, Fear, Happiness, Sadness, Surprise, prediction.

ðŸ§  Model Architecture
We utilize a custom CNN (CustomEmotionCNN) defined in src/model.py:
   Input: 64x64 RGB Images.
   Backbone: 4 Convolutional Blocks (Conv2d -> BatchNorm -> ReLU -> MaxPool).
   Classifier: Fully Connected layers with Dropout (0.5) for regularization.
   Classes: Anger, Disgust, Fear, Happiness, Sadness, Surprise.

ðŸ“Š Results
Current Accuracy: ~69% (Baseline Model v3)
Strongest Class: Happiness
Challenges: Face Alignment
            Distinguishing Fear vs. Surprise due to visual similarities and limited data representation.

University of Munich (LMU) - WiSe 25/26