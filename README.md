# SEP: Computer Vision & Deep Learning Project

This project implements a Convolutional Neural Network (CNN) to classify facial emotions using the **RAF-DB (Real-world Affective Faces Database)**. It is part of the Software Development Practical Course (SEP).

## ðŸ‘¥ Team Members
* Alen Alija
* Kilian Killer
* Leon Maibauer
* Richard Tscharke

## ðŸ“‚ Project Structure

```text
.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ RAF_raw/                # Place original dataset here (aligned & original folders)
â”‚   â”œâ”€â”€ RAF_aligned_processed/  # Generated by prepare_RAF_raw.py (used for training)
â”‚   â””â”€â”€ RAF_original_processed/ # Generated by prepare_RAF_raw.py (full size images)
â”œâ”€â”€ models/                  # Saved model checkpoints (*.pth)
â”œâ”€â”€ results/                 # Output CSVs and evaluation metrics
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ demo.py              # 
â”‚   â”œâ”€â”€ evaluate.py          # Generates confusion matrix & report
â”‚   â”œâ”€â”€ explain.py           # 
â”‚   â”œâ”€â”€ generate_csv.py      # Generates predictions.csv
â”‚   â”œâ”€â”€ merge.py             # 
â”‚   â”œâ”€â”€ model.py             # CNN Architecture definition
â”‚   â”œâ”€â”€ prepare_KDEF.py      # 
â”‚   â”œâ”€â”€ prepare_RAF_raw.py   # Data preprocessing script
â”‚   â”œâ”€â”€ preprocess_KDEF.py   #
â”‚   â”œâ”€â”€ preprocess_RAF_raw.py   # 
â”‚   â””â”€â”€ train.py             # Main training loop
â”œâ”€â”€ requirements.txt         # Python dependencies
â””â”€â”€ README.md


ðŸ› ï¸ Installation & Setup
1. Clone the repository (if not already done).
2. Create and activate a virtual environment (recommended):
   python3 -m venv .venv
   source .venv/bin/activate  # On Windows: .venv\Scripts\activate
3. Install dependencies:
   pip install -r requirements.txt


ðŸš€ Workflow
1. Data Preparation and Preprocessing

1.1 RAF Dataset

- Create a new directory called "RAF_raw" inside the project's data directory.
- Copy the "EmoLabel" and "Image" directories from the official RAF database into "data/RAF_raw/".
- IMPORTANT: To use our self-developed face alignment method, delete the "aligned" directory inside "Image".
- Run the preprocessing script:
  python src/preprocess_RAF_raw.py
- Run the preparation script:
  python src/prepare_RAF_raw.py

This script creates two directories:
- data/RAF_aligned_processed/ (used for training)
- data/RAF_original_processed/ (full-size images)

Each directory contains subfolders for the following emotion classes:
- Anger
- Disgust
- Fear
- Happiness
- Sadness
- Surprise

Data directory structure after Step 1.1:

data/
â”œâ”€â”€ RAF_raw/
â”œâ”€â”€ RAF_aligned_processed/
â””â”€â”€ RAF_original_processed/

---

1.2 KDEF Dataset

- Place the official "KDEF" dataset inside the "data" directory.
- Run the preparation script:
  python src/prepare_KDEF.py
- Run the preprocessing script:
  python src/preprocess.py

Data directory structure after Steps 1.1 and 1.2:

data/
â”œâ”€â”€ KDEF/
â”‚   â”œâ”€â”€ AF01/
â”‚   â”œâ”€â”€ BM35/
â”‚   â”œâ”€â”€ ...
â”‚   â”œâ”€â”€ EmoLabel/
â”‚   â””â”€â”€ Image/
â”‚       â”œâ”€â”€ KDEF_aligned_processed/
â”‚       â””â”€â”€ KDEF_original_processed/
â”œâ”€â”€ RAF_raw/
â”œâ”€â”€ RAF_aligned_processed/
â””â”€â”€ RAF_original_processed/

---

1.3 Merging RAF and KDEF

- To use KDEF as additional training data (currently training only),
  add the aligned and processed KDEF images to the corresponding emotion
  folders in "RAF_aligned_processed/".
- Run the merging script:
  python src/merge.py


2. Training the Model: 
To train the CNN from scratch:
   python src/train.py
Input: Images from data/RAF_aligned_processed/train. Or use the original Images 
Output: Saves the best model weights to models/raf_cnn_vX.pth (automatically versioned).
Config: You can adjust BATCH_SIZE, LEARNING_RATE, and EPOCHS directly in src/train.py.

3. Evaluation:
To generate a classification report and a confusion matrix:
   I Ensure the correct model path is set in src/evaluate.py (variable MODEL_PATH).
   II Run:
      python src/evaluate.py
   III Output: Prints precision/recall/f1-score to console and saves confusion_matrix.png

4. Generate Submission CSV
To generate the required CSV file containing classification scores for the test set:
   python src/generate_csv.py
Output: Saves predictions.csv to the results/ folder.
Format: filename, Anger, Disgust, Fear, Happiness, Sadness, Surprise, prediction.

ðŸ§  Model Architecture
We utilize a custom CNN (CustomEmotionCNN) defined in src/model.py:
   Input: 64x64 RGB Images.
   Backbone: 4 Convolutional Blocks (Conv2d -> BatchNorm -> ReLU -> MaxPool).
   Classifier: Fully Connected layers with Dropout (0.5) for regularization.
   Classes: Anger, Disgust, Fear, Happiness, Sadness, Surprise.

ðŸ“Š Results
Current Accuracy: ~82% (Model v5)
Strongest Class: Happiness
Challenges: 
Distinguishing Fear vs. Disgust due to visual similarities and limited data representation.

University of Munich (LMU) - WiSe 25/26
